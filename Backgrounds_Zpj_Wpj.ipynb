{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import uproot\n",
    "import awkward\n",
    "import mplhep as hep\n",
    "import glob\n",
    "hep.style.use(\"CMS\")\n",
    "\n",
    "\n",
    "Path_files = \"/home/tomas/U1_LQ\"\n",
    "\n",
    "\n",
    "class RootTreeReader:\n",
    "\n",
    "    \"\"\" \n",
    "    Read data from a ROOT TTree \n",
    "    Parameters:\n",
    "    path : string\n",
    "        Path to the ROOT file\n",
    "    tree_name : string (default=Delphes)\n",
    "        Name of the ROOT TTree\n",
    "    Attributes:\n",
    "    tree: Root TTree \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str, tree_name: str = \"Delphes\"):\n",
    "        self.tree = uproot.open(path)[tree_name]\n",
    "\n",
    "\n",
    "    def get_branches(self, branches = [\"MissingET.MET\",\n",
    "                                       \"MissingET.Eta\",\n",
    "                                       \"MissingET.Phi\",\n",
    "                                       \"Jet.PT\",\n",
    "                                       \"Jet.Eta\",\n",
    "                                       \"Jet.Phi\",\n",
    "                                       \"Jet.Mass\",\n",
    "                                       \"Jet.TauTag\",\n",
    "                                       \"Jet.BTag\",\n",
    "                                       \"Jet_size\"], max_elements=4):\n",
    "        \"\"\"\n",
    "        returns a DataFrame with branches as features\n",
    "        branches : array-like\n",
    "          branches to load from the ROOT tree\n",
    "        max_elements : int (default=4)\n",
    "          maximum number of elements to load from jagged arrays\n",
    "        \"\"\"   \n",
    "        self._max_elements = max_elements\n",
    "        self._df = pd.DataFrame(index=range(self.tree.num_entries))\n",
    "\n",
    "        for branch in branches:\n",
    "            self._join_branch(branch)\n",
    "\n",
    "        return self._set_columns_names(self._df)\n",
    "\n",
    "\n",
    "    def _join_branch(self, branch):\n",
    "        \"\"\"joins a branch to self._df\"\"\"\n",
    "        df = self.tree.arrays(branch, library=\"pd\")\n",
    "\n",
    "        if \".\" in branch:\n",
    "            if len(df) > len(df.groupby(level=0).size()):\n",
    "                self._add_jagged_branch(df, branch)\n",
    "            else:\n",
    "                self._add_branch(df, branch)\n",
    "        else:\n",
    "            self._add_branch(df, branch)\n",
    "\n",
    "\n",
    "    def _add_branch(self, df, branch: str):\n",
    "        \"\"\"adds a non-jagged branch to self.df\"\"\"\n",
    "        self._df[branch] = self.tree[branch].array(library=\"pd\").values\n",
    "\n",
    "\n",
    "    def _add_jagged_branch(self, df, branch):\n",
    "        \"\"\"adds a jagged branch to self.df\"\"\"\n",
    "        df = df.unstack().iloc[:,:self._max_elements]\n",
    "        df.columns = [\"{0}{1}\".format(branch, i) for i in range(self._max_elements)]\n",
    "        self._df = self._df.join(df)\n",
    "\n",
    "    @staticmethod\n",
    "    def _set_columns_names(df):\n",
    "        df.columns = df.columns.str.lower().str.replace(\".\",\"_\")\n",
    "        return df\n",
    "\n",
    "\n",
    "def build_df(path):\n",
    "    \"\"\"\n",
    "    Generates a Dataframe from the root in \"path\"\n",
    "    \"\"\"\n",
    "    reader = RootTreeReader(path)\n",
    "    df = reader.get_branches()\n",
    "    df[\"n_b\"]  =  reader.tree.arrays(\"Jet.BTag\", library=\"pd\").sum(level=0)\n",
    "    df[\"n_tau\"] = reader.tree.arrays(\"Jet.TauTag\", library=\"pd\").sum(level=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def tau_cut(df, val = 0):\n",
    "    mask = (df.n_tau > val) & (df.jet_tau_index1 >= 0)\n",
    "    return df.loc[mask]\n",
    "\n",
    "def b_cut(df, val = 0):\n",
    "    mask = (df.n_b > val) & (df.jet_b_index1 >= 0)\n",
    "    return df.loc[mask]\n",
    "\n",
    "\n",
    "#Cuts over the final Df\n",
    "\n",
    "def pt_tau_cut(df, val = 25):\n",
    "    # leading jets pt > 30 GeV\n",
    "    mask = df.tau1_pT > val\n",
    "    return df.loc[mask]\n",
    "\n",
    "\n",
    "def pt_b_cut(df, val = 30):\n",
    "    # leading jets pt > 30 GeV\n",
    "    mask = df.b_pT > val\n",
    "    return df.loc[mask]\n",
    "\n",
    "\n",
    "def eta_tau_cut(df, val = 2.4):\n",
    "    # leading jets eta < 2.4\n",
    "    mask = np.abs(df.tau1_eta) < val\n",
    "    return df.loc[mask]\n",
    "\n",
    "\n",
    "def eta_b_cut(df, val = 2.1):\n",
    "    # leading jets eta < 2.4\n",
    "    mask = np.abs(df.b_eta) < val\n",
    "    return df.loc[mask]\n",
    "\n",
    "\n",
    "def phi_tau_cut(df, val= 2.0):\n",
    "    # delta phi between met and tau > 2.0\n",
    "    mask = np.abs(df.Delta_phi_Tau_Met) > val\n",
    "    return df.loc[mask]\n",
    "\n",
    "\n",
    "def et_met_cut(df, val = 200):\n",
    "    # Met et greater than 200\n",
    "    mask = df.met_Met > val\n",
    "    return df.loc[mask]\n",
    "\n",
    "\n",
    "def final_cuts(df, pt_tau = 25, pt_b = 20, eta_tau = 2.3, eta_b = 2.5, met = 150, del_phi = 1.0):\n",
    "    \"\"\"\n",
    "    Returns a copy of the df filtered by different variables and different objects\n",
    "    Parameters:\n",
    "        df : A Pandas.Dataframe to be filtered. This DataFrame must have a series of columns named as \n",
    "             'tau_pT' ,'tau_eta' ,'tau_phi' ,'tau_mass', 'b_pT' ,'b_eta' ,'b_phi' ,\n",
    "             'b_mass','met_Met' ,'met_Phi' ,'met_Eta', 'n_tau', 'n_b'.\n",
    "        pt_tau : Minimun value for tau's p_T.\n",
    "        pt_b : Minimun value for b's p_T.\n",
    "        eta_tau : Minimun value for tau's eta.\n",
    "        eta_b : Minimun value for b's eta.\n",
    "        met : Minimun value for p_T^{miss}. \n",
    "        del_phi : Minimun value for absolute value of delta phi between tau and met.\n",
    "    \"\"\"\n",
    "    cut_df = df.copy()\n",
    "    cut_df = pt_tau_cut(cut_df, pt_tau)\n",
    "    cut_df = pt_b_cut(cut_df, pt_b)\n",
    "    cut_df = eta_tau_cut(cut_df, eta_tau)\n",
    "    cut_df = phi_tau_cut(cut_df, del_phi)\n",
    "    cut_df = eta_b_cut(cut_df, eta_b)\n",
    "    cut_df = et_met_cut(cut_df, met)\n",
    "    return cut_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def branch_index(df, branch):\n",
    "    \"\"\"\n",
    "    Adds a column with the index of the first jet tagged as branch to the df.\n",
    "\n",
    "    Branch:\n",
    "    takes values of \"jet_btag\" or \"jet_tautag\"\n",
    "\n",
    "    Ex:\n",
    "    branch_index(cut_df, \"jet_tautag\")\n",
    "    Returns a df with a column with the first jet tagged as tau per ivent\n",
    "    \"\"\"\n",
    "    branch_jets = df[[f\"{branch}{i}\" for i in range(4)]].copy()\n",
    "\n",
    "    # events with branch jets\n",
    "    branch_events1 = branch_jets[branch_jets.sum(axis=1) > 0]\n",
    "    \n",
    "    # events with more tah 1 branch jets\n",
    "    branch_events2 = branch_jets[branch_jets.sum(axis=1) > 1]\n",
    "\n",
    "    # index of first branch jet\n",
    "    branch_index1 = branch_events1.apply(lambda x: x > 0).apply(lambda x: np.nonzero(x.values)[0][0], axis=1)\n",
    "    \n",
    "    # index of first branch jet\n",
    "    branch_index2 = branch_events2.apply(lambda x: x > 0).apply(lambda x: np.nonzero(x.values)[0][1], axis=1)\n",
    "\n",
    "    # index of non branch jets (set to nan)\n",
    "    branch_nan = pd.DataFrame(index= branch_jets[branch_jets.sum(axis=1) == 0].index)\n",
    "\n",
    "    # branch jet index\n",
    "    df[\"{}_index1\".format(branch).replace('tag','')] = pd.concat([branch_index1,branch_nan]).sort_index()\n",
    "    df[\"{}_index2\".format(branch).replace('tag','')] = pd.concat([branch_index2,branch_nan]).sort_index()\n",
    "\n",
    "    return df , branch_index1, branch_index2\n",
    "\n",
    "def DeltaPhi(row, col1 = 'tau1_phi', col2 = 'met_Phi'):\n",
    "    \"\"\"\n",
    "    correction on azimuthal angle difference dphi\n",
    "    \"\"\"\n",
    "    dphi = row[col1] - row[col2]\n",
    "    if dphi >= np.pi: \n",
    "        dphi -= 2*np.pi\n",
    "    if dphi < -np.pi:\n",
    "        dphi += 2*np.pi\n",
    "\n",
    "    return dphi\n",
    "\n",
    "\n",
    "def m_Tot(row):  \n",
    "    #Calculates TotalMass from 5.4  https://arxiv.org/pdf/1709.07242.pdf   \n",
    "    pt1 = row['tau_pT']\n",
    "    px1 = row['tau_pT'] * np.cos(row['tau_phi'])\n",
    "    py1 = row['tau_pT'] * np.sin(row['tau_phi'])\n",
    "    pt2 = row['b_pT']\n",
    "    px2 = row['b_pT'] * np.cos(row['b_phi'])\n",
    "    py2 = row['b_pT'] * np.sin(row['b_phi'])\n",
    "    met_pt3 = row['met_Met']\n",
    "    px3 = met_pt3 * np.cos(row['met_Phi'])\n",
    "    py3 = met_pt3 * np.sin(row['met_Phi'])\n",
    "\n",
    "\n",
    "    vec1 = np.array([px1 , py1])\n",
    "    vec2 = np.array([px2 , py2])\n",
    "    vec3 = np.array([px3 , py3])\n",
    "    vect_t = vec1 + vec2 + vec3 \n",
    "    vec_t2 = np.dot(vect_t, vect_t)\n",
    "    sum_escal = (pt1 + pt2 + met_pt3) **2\n",
    "    return (sum_escal - vec_t2  ) ** 0.5\n",
    "\n",
    "\n",
    "def transverse_mass(tau_pt, met_et, deltaphi):\n",
    "    #Calculates the transverse mass between tau (or any other jet) and the met\n",
    "    return np.sqrt(2 * tau_pt * met_et * (1 - np.cos(deltaphi)))\n",
    "\n",
    "\n",
    "def invariant_mass(obj1_pt, obj1_eta, obj2_pt, obj2_eta, deltaphi ):\n",
    "    #Calculates the invariant mass for 2 different objects\n",
    "    return np.sqrt(2 * obj1_pt * obj2_pt * (np.cosh(obj1_eta-obj2_eta) - np.cos(deltaphi)))\n",
    "\n",
    "\n",
    "def Get_Pt_Eta_Phi_Tau_B(row):\n",
    "    \"\"\"\n",
    "    Returns a row with a list of the Pt, Eta, Phi\n",
    "    of the Taus and B's (in the respective order)\n",
    "    Needs a column named Tau_b_Tuple.\n",
    "    \"\"\"\n",
    "    if pd.isna(row['jet_tau_index2']):\n",
    "        \n",
    "        n_tau1 = int(row['jet_tau_index1'])\n",
    "        n_tau2 = np.NaN\n",
    "        n_b1 = int(row['jet_b_index1'])\n",
    "        num_b = row['n_b']\n",
    "\n",
    "        s = pd.Series(cols)\n",
    "        s1 = list(s[s.astype(str).str[-1] == str(n_tau1)][:4])\n",
    "        #s1_2 = list(s[s.astype(str).str[-1] == str(n_tau2)][:4])\n",
    "        s2 = list(s[s.astype(str).str[-1] == str(n_b1)][:4])\n",
    "\n",
    "\n",
    "        tau_pT1 = row[str(s1[0])] \n",
    "        tau_eta1 = row[str(s1[1])] \n",
    "        tau_phi1 = row[str(s1[2])] \n",
    "        tau_mass1 = row[str(s1[3])]\n",
    "\n",
    "        tau_pT2 = np.NaN\n",
    "        tau_eta2 = np.NaN \n",
    "        tau_phi2 = np.NaN \n",
    "        tau_mass2 = np.NaN\n",
    "\n",
    "        b_pT = row[str(s2[0])] \n",
    "        b_eta = row[str(s2[1])] \n",
    "        b_phi = row[str(s2[2])] \n",
    "        b_mass = row[str(s2[3])]\n",
    "\n",
    "        met_Met = row['missinget_met']\n",
    "        met_Phi = row['missinget_phi']\n",
    "        met_Eta = row['missinget_eta']\n",
    "        \n",
    "    else:\n",
    "        n_tau1 = int(row['jet_tau_index1'])\n",
    "        n_tau2 = int(row['jet_tau_index2'])\n",
    "        n_b1 = int(row['jet_b_index1'])\n",
    "        num_b = row['n_b']\n",
    "\n",
    "        s = pd.Series(cols)\n",
    "        s1 = list(s[s.astype(str).str[-1] == str(n_tau1)][:4])\n",
    "        s1_2 = list(s[s.astype(str).str[-1] == str(n_tau2)][:4])\n",
    "        s2 = list(s[s.astype(str).str[-1] == str(n_b1)][:4])\n",
    "\n",
    "\n",
    "        tau_pT1 = row[str(s1[0])] \n",
    "        tau_eta1 = row[str(s1[1])] \n",
    "        tau_phi1 = row[str(s1[2])] \n",
    "        tau_mass1 = row[str(s1[3])]\n",
    "\n",
    "        tau_pT2 = row[str(s1_2[0])] \n",
    "        tau_eta2 = row[str(s1_2[1])] \n",
    "        tau_phi2 = row[str(s1_2[2])] \n",
    "        tau_mass2 = row[str(s1_2[3])]\n",
    "\n",
    "        b_pT = row[str(s2[0])] \n",
    "        b_eta = row[str(s2[1])] \n",
    "        b_phi = row[str(s2[2])] \n",
    "        b_mass = row[str(s2[3])]\n",
    "\n",
    "        met_Met = row['missinget_met']\n",
    "        met_Phi = row['missinget_phi']\n",
    "        met_Eta = row['missinget_eta']\n",
    "\n",
    "    return (tau_pT1, tau_eta1, tau_phi1, tau_mass1, \n",
    "            tau_pT2, tau_eta2, tau_phi2, tau_mass2, \n",
    "            b_pT, b_eta, b_phi, b_mass, \n",
    "            met_Met, met_Phi, met_Eta, n_tau1, num_b, n_b1)\n",
    "\n",
    "def generate_data_b_tau_nu(df):\n",
    "    \"\"\"Returns a Dataframe with the information per event\n",
    "    of the tau_jet and the missin energy.\n",
    "    The index preserves the index from the original dataframe.\n",
    "    Arguments:\n",
    "        df :  dataframe generated with \n",
    "        get_braches(\"MissingET.MET\",\"MissingET.Eta\",\"MissingET.Phi\",\"Jet.PT\",\n",
    "                    \"Jet.Eta\",\"Jet.Phi\",\"Jet.Mass\",\"Jet.TauTag\",\"Jet.BTag\",\"Jet_size\")\n",
    "\n",
    "    Also the dataframe must content a column named as n_tau as the number of taus per event\n",
    "    Columns : \n",
    "        'tau_pT' ,'tau_eta' ,'tau_phi' ,'tau_mass', 'b_pT' ,'b_eta' ,'b_phi' ,\n",
    "        'b_mass','met_Met' ,'met_Phi' ,'met_Eta', 'n_tau', 'n_b'.\n",
    "\n",
    "    \"\"\"\n",
    "    cut_df, tau_index1, tau_index2  = branch_index(df, 'jet_tautag')\n",
    "    cut_df, b_index1, b_index2 = branch_index(cut_df, 'jet_btag')\n",
    "    #cut_df, tau_index = branch_index(df, 'jet_tautag')\n",
    "    #cut_df, tau_index = branch_index(cut_df, 'jet_btag')\n",
    "    cut_df = tau_cut(cut_df)\n",
    "    cut_df = b_cut(cut_df)\n",
    "\n",
    "    s = cut_df.apply(Get_Pt_Eta_Phi_Tau_B, axis = 1)\n",
    "    Df = pd.DataFrame(s.to_list(), index = s.index, \n",
    "                      columns=['tau1_pT' ,\n",
    "                               'tau1_eta' ,\n",
    "                               'tau1_phi' ,\n",
    "                               'tau1_mass', \n",
    "                               'tau2_pT', \n",
    "                               'tau2_eta', \n",
    "                               'tau2_phi', \n",
    "                               'tau2_mass',\n",
    "                               'b_pT' ,\n",
    "                               'b_eta' ,\n",
    "                               'b_phi' ,\n",
    "                               'b_mass',\n",
    "                               'met_Met' ,\n",
    "                               'met_Phi' ,\n",
    "                               'met_Eta' ,\n",
    "                               'n_tau1', \n",
    "                               'num_b', 'n_b1'])\n",
    "  \n",
    "    Df['Delta_phi_Tau_Met'] = Df.apply(DeltaPhi,axis = 1)\n",
    "    Df['Delta_phi_B_Met'] = Df.apply(DeltaPhi,axis = 1, args=('b_phi', 'met_Phi'))\n",
    "    Df['Delta_phi_Tau_B'] = Df.apply(DeltaPhi,axis = 1, args=('tau1_phi', 'b_phi'))\n",
    "    Df = Df.copy()[Df.n_tau1 != Df.n_b1]\n",
    "    return Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = glob.glob(\"/cms/mc/Samples/SMWtaunu_btaunu_analysis/*.root\")\n",
    "lz = glob.glob(\"/cms/mc/MG5_aMC_v3_1_1/DY+jets/Events/*/*.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_12.root',\n",
       " '/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_03.root',\n",
       " '/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_14.root',\n",
       " '/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_04.root',\n",
       " '/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_06.root',\n",
       " '/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_11.root',\n",
       " '/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_09.root',\n",
       " '/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_08.root',\n",
       " '/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_07.root',\n",
       " '/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_13.root',\n",
       " '/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_10.root',\n",
       " '/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_05.root',\n",
       " '/cms/mc/Samples/SMWtaunu_btaunu_analysis/run_15.root']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1814853/3288760798.py:83: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.columns = df.columns.str.lower().str.replace(\".\",\"_\")\n",
      "/tmp/ipykernel_1814853/3288760798.py:93: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  df[\"n_b\"]  =  reader.tree.arrays(\"Jet.BTag\", library=\"pd\").sum(level=0)\n",
      "/tmp/ipykernel_1814853/3288760798.py:94: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  df[\"n_tau\"] = reader.tree.arrays(\"Jet.TauTag\", library=\"pd\").sum(level=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se produjo Z +jets con 88419\n"
     ]
    }
   ],
   "source": [
    "l_dfz = []\n",
    "l_z_e_mu = []\n",
    "for path in lz:\n",
    "    df_z = build_df(path)\n",
    "    l_dfz.append(df_z)\n",
    "    reader = RootTreeReader(path)\n",
    "    df_e_mu = reader.get_branches(branches=[\"Electron.PT\"], max_elements=1)\n",
    "    try:\n",
    "        mu = reader.get_branches(branches=[\"Muon.PT\"], max_elements=1)\n",
    "        df_e_mu['muon_pt'] = mu.iloc[:,0]\n",
    "    except:\n",
    "        print(f\"No se pudo llenar con la rama de muones para la {path[-11::]}\")\n",
    "        df_e_mu['muon_pt'] = np.NaN\n",
    "    l_z_e_mu.append(df_e_mu)\n",
    "    \n",
    "\n",
    "df_zpj = pd.concat([df for df in l_dfz],ignore_index= True)\n",
    "df_zpj_e_mu = pd.concat([df for df in l_z_e_mu],ignore_index= True)\n",
    "cols = df_zpj.columns\n",
    "print(f\"Se produjo Z +jets con {df_zpj.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1814853/3288760798.py:83: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.columns = df.columns.str.lower().str.replace(\".\",\"_\")\n",
      "/tmp/ipykernel_1814853/3288760798.py:93: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  df[\"n_b\"]  =  reader.tree.arrays(\"Jet.BTag\", library=\"pd\").sum(level=0)\n",
      "/tmp/ipykernel_1814853/3288760798.py:94: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  df[\"n_tau\"] = reader.tree.arrays(\"Jet.TauTag\", library=\"pd\").sum(level=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo llenar con la rama de muones para la run_06.root\n",
      "No se pudo llenar con la rama de muones para la run_15.root\n",
      "Se produjo W +jets con 350495\n"
     ]
    }
   ],
   "source": [
    "l_dfw = []\n",
    "l_w_e_mu = []\n",
    "for path in lw:\n",
    "    df_w = build_df(path)\n",
    "    l_dfw.append(df_w)\n",
    "    reader = RootTreeReader(path)\n",
    "    df_e_mu = reader.get_branches(branches=[\"Electron.PT\"], max_elements=1)\n",
    "    try:\n",
    "        mu = reader.get_branches(branches=[\"Muon.PT\"], max_elements=1)\n",
    "        df_e_mu['muon_pt'] = mu.iloc[:,0]\n",
    "    except:\n",
    "        print(f\"No se pudo llenar con la rama de muones para la {path[-11::]}\")\n",
    "        df_e_mu['muon_pt'] = np.NaN\n",
    "    l_w_e_mu.append(df_e_mu)\n",
    "    \n",
    "\n",
    "df_wpj = pd.concat([df for df in l_dfw],ignore_index= True)\n",
    "df_wpj_e_mu = pd.concat([df for df in l_w_e_mu],ignore_index= True)\n",
    "cols = df_wpj.columns\n",
    "print(f\"Se produjo W +jets con {df_wpj.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_bg_wj = generate_data_b_tau_nu(df_wpj)\n",
    "Df_bg_zj = generate_data_b_tau_nu(df_zpj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_bg_wj['electron_pT'] = df_wpj_e_mu.loc[Df_bg_wj.index,'electron_pt0']\n",
    "Df_bg_wj['muon_pT'] = df_wpj_e_mu.loc[Df_bg_wj.index,'muon_pt']\n",
    "Df_bg_zj['electron_pT'] = df_zpj_e_mu.loc[Df_bg_zj.index,'electron_pt0']\n",
    "Df_bg_zj['muon_pT'] = df_zpj_e_mu.loc[Df_bg_zj.index,'muon_pt']\n",
    "\n",
    "Df_bg_wj.to_csv(\"/home/tomas/w+jets_e_mu_one_b.csv\")\n",
    "Df_bg_zj.to_csv(\"/home/tomas/z+jets_e_mu_one_b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((104, 23), (65, 23))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = 250\n",
    "odp = 1.5\n",
    "omet = 200\n",
    "\n",
    "\n",
    "Df_bgw_cut = final_cuts(Df_bg_wj, pt_tau = opt, pt_b=20, del_phi = odp, met = omet)\n",
    "Df_bgz_cut = final_cuts(Df_bg_zj, pt_tau = opt, pt_b=20, del_phi = odp, met = omet)\n",
    "\n",
    "Df_bgw_cut = Df_bgw_cut[Df_bgw_cut.num_b == 1]\n",
    "Df_bgz_cut = Df_bgz_cut[Df_bgz_cut.num_b == 1]\n",
    "\n",
    "Df_bgw_cut = Df_bgw_cut[(Df_bgw_cut.electron_pT < 15) | ((Df_bgw_cut.electron_pT.isna()))]\n",
    "Df_bgw_cut = Df_bgw_cut[(Df_bgw_cut.muon_pT < 15)     | ((Df_bgw_cut.muon_pT.isna()))]\n",
    "Df_bgz_cut = Df_bgz_cut[(Df_bgz_cut.electron_pT < 15) | ((Df_bgz_cut.electron_pT.isna()))]\n",
    "Df_bgz_cut = Df_bgz_cut[(Df_bgz_cut.muon_pT < 15)     | ((Df_bgz_cut.muon_pT.isna()))]\n",
    "\n",
    "Df_bgw_cut = Df_bgw_cut[(Df_bgw_cut.tau2_pT < 50) | ((Df_bgw_cut.tau2_pT.isna()))]\n",
    "Df_bgw_cut = Df_bgw_cut[(np.abs(Df_bgw_cut.tau2_eta) > 2.3) | ((Df_bgw_cut.tau2_eta.isna()))]\n",
    "Df_bgz_cut = Df_bgz_cut[(Df_bgz_cut.tau2_pT < 50) | ((Df_bgz_cut.tau2_pT.isna()))]\n",
    "Df_bgz_cut = Df_bgz_cut[(np.abs(Df_bgz_cut.tau2_eta) > 2.3) | ((Df_bgz_cut.tau2_eta.isna()))]\n",
    "\n",
    "Df_bgw_cut.shape, Df_bgz_cut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
